\chapter{Dataset Creation and Annotation}

As presented by the previous chapter, the performance of machine learning models is highly dependent on the quality and quantity of the training data. In this chapter, we describe the process of creating and annotating the dataset used for training and evaluating our model.

\section{Dataset Creation}

Since for this study we only required a dataset of the email body content labeled for its emotions, we created our own dataset by taking the existing dataset used in \cite{Fernandes2024} and feeding it into a \ac{LLM} to generate a larger dataset. 

The dataset used required no preprocessing, as it was already in a clean, well-structured format tailored for our needs. The dataset consisted of approximately 480 samples of email body content, each labeled with one of fourteen possible emotions.

To create our dataset, we took all emails related to a certain emotion and prompted the Ollama \ac{LLM} to generate additional samples by providing context and examples, using the following prompt template:

\begin{tcolorbox}[colback=gray!10, colframe=gray!60, title={Prompt Template}]
Based on these examples of emails expressing '{emotion}', generate 1 new realistic phishing email that captures the same emotional tone and style. Make it convincing and professional, evoking the emotion of {emotion}.

Generate only the email content, no additional text or explanations: \textit{Example emails here}
\end{tcolorbox}


Using this method, we were able to create a new dataset with 10,000 samples, equatily distributed across the fourteen emotions. This expanded dataset provided a robust foundation for training our machine learning models to accurately classify the emotional content of phishing emails.

Below is an example of a generated email for the emotion "Admiration":

\begin{tcolorbox}[colback=gray!5, colframe=gray!40, title={Example Email — Admiration}]
\obeylines
\textbf{Subject:} A surprise awaits you — Unlock your exclusive benefits today!

Dear [Recipient],

We hope this message finds you well and thriving! We're thrilled to inform you that our records indicate an outstanding opportunity for you — one that we believe will bring joy and appreciation to your day.

Over the years, you've been a valued member of our community. Your dedication, passion, and unwavering commitment have not gone unnoticed. In recognition of your remarkable journey with us, we're delighted to offer you a special surprise — an exclusive upgrade on your current subscription plan with our esteemed organization.

This gesture is but a small token of admiration for your contributions and the positive impact you've made. We trust this unexpected delight will bring a smile to your face and serve as a reminder that your efforts are truly valued.

To unveil the details of your special benefits, please click on the following link: [suspicious link]

Warmest regards,
[Your Name]
[Your Position/Title]
[Organization Name]
\end{tcolorbox}

\section{Annotation Guidelines}

To ensure consistency and accuracy in the annotation process, we established a set of guidelines for annotators to follow. These guidelines included a set of general rules as a way to standardize the annotation process and remove ambiguity, as well as specific instructions for each emotion category, including an example of a phrase that would typically express that emotion.

\section{Dataset Annotation}

With the dataset created, and guidelines set, we proceeded to annotate the dataset. Given that the dataset was generated using a \ac{LLM} with specific prompts, each sample was inherently labeled with the intended emotion. However, to ensure the quality and accuracy of these labels, we conducted a manual review process.

Since it's infeasible to annotate all 10,000 samples with just one annotator, and to eliminate potential biases, we decided on using a annotation plataform called Doccano \cite{doccano} hosted on a DigitalOcean \ac{VM} \cite{digitalocean}. This platform allows multiple annotators to work on the same dataset, providing a collaborative environment for annotation.
