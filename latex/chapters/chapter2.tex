\chapter{State of the Art}

This chapter provides a comprehensive examination of the current state of research in phishing email detection, with particular emphasis on machine learning approaches and the emerging role of sentiment analysis. The chapter is structured to first establish the technical foundations of email communication and phishing attacks, followed by an in-depth analysis of detection methodologies, and concluding with an examination of available datasets and their limitations. This review identifies critical gaps in existing research that motivate the work presented in subsequent chapters.

\section{Email Communication: Technical Foundations and Security Implications}

\subsection{Email Architecture and Standards}

Electronic mail (e-mail) represents one of the most enduring and ubiquitous forms of digital communication, with an estimated 4.37 billion users worldwide and over 333 billion emails sent daily as of 2023. Despite the proliferation of alternative communication platforms, email remains the dominant medium for formal business communication, personal correspondence, and increasingly, as a primary vector for sophisticated cyber attacks.

The technical architecture of email is governed by a suite of Internet standards that define message format, transmission protocols, and security mechanisms. At its core, the Internet Message Format standard (\acs{RFC} 5322) specifies the structure of email messages, including mandatory header fields (From, Date, To) and optional fields (Subject, Reply-To, CC, BCC) that provide metadata about message routing and handling \cite{rfc5322}. 

This specification was subsequently updated by \acs{RFC} 6854 to support group syntax in sender fields, enabling more flexible representation of multiple authors or organizational senders \cite{rfc6854}.

Email messages are typically stored and exchanged using the .eml file format, which encapsulates the complete message structure including headers, body content, and attachments according to the \ac{MIME} standard. This format preserves critical forensic information such as authentication results (\ac{SPF}, \ac{DKIM}, \ac{DMARC} records), complete routing paths (Received headers), message identifiers, and content characteristics that are essential for both manual analysis and automated detection systems. The preservation of this metadata makes .eml files particularly valuable for research purposes, as they provide access to the full spectrum of features that can be leveraged for phishing detection.

\subsection{Email as an Attack Vector}

The widespread adoption and inherent trust associated with email communication have made it an ideal vector for malicious activities. Several characteristics of email infrastructure contribute to its vulnerability and create conditions favorable to sophisticated attacks.

First, users typically assume emails from seemingly legitimate sources are authentic, particularly when they employ familiar branding, professional language, or appear to originate from known contacts or institutions. This implicit trust, rooted in decades of email communication norms, creates substantial opportunities for social engineering attacks that exploit human psychology rather than technical vulnerabilities. Attackers routinely leverage this fundamental trust assumption to establish initial credibility for their campaigns.

Second, despite the existence of authentication protocols like \ac{SPF}, \ac{DKIM}, and \ac{DMARC}, these mechanisms are not universally implemented across email infrastructure, and their absence or misconfiguration allows attackers to forge sender information with relative ease. Furthermore, even properly authenticated emails can be legitimate in origin but malicious in intent, as exemplified by business email compromise scenarios where attackers gain access to legitimate accounts through prior phishing or credential theft and subsequently weaponize those accounts to send fraudulent messages that pass all authentication checks.

Third, modern email systems support HTML rendering, embedded images, clickable links, and attachments, providing multiple distinct avenues for delivering malicious content. This technical richness creates numerous attack surfaces that can be exploited through various techniques including malicious links that redirect to phishing sites, weaponized attachments containing ransomware or spyware, embedded tracking pixels for reconnaissance and victim profiling, and CSS-based rendering tricks designed to obfuscate malicious content from both automated security scanners and human analysts.

Finally, attackers can easily automate the creation and distribution of phishing emails at massive scale, enabling campaigns that target thousands or millions of recipients with minimal cost or effort per recipient. This asymmetry between the attacker's investment and potential return makes email-based attacks economically attractive and persistent, allowing threat actors to maintain active campaigns despite defensive countermeasures.

These vulnerabilities collectively underscore the critical need for robust, multi-layered detection mechanisms that can identify malicious emails before they reach end users and cause harm.

\section{Phishing: Taxonomy, Evolution, and Impact}

\subsection{Definition and Taxonomy}

Phishing is a form of cyber attack in which adversaries attempt to deceive individuals into divulging sensitive information, such as credentials, financial details, or personal data, by masquerading as trustworthy entities through electronic communication. While email remains the predominant delivery mechanism, phishing has expanded to encompass SMS-based variants known as smishing, voice-based attacks called vishing, and attacks through social media platforms, reflecting the attack methodology's remarkable adaptability to different communication channels.

Phishing attacks can be taxonomically categorized along several dimensions that reflect the attacker's targeting approach, intended objective, and technical sophistication. Regarding targeting strategy, attacks range from bulk phishing campaigns that send indiscriminate messages to large recipient lists with generic content designed to appeal to universal concerns such as account security, package delivery delays, or unexpected tax refunds. More sophisticated variants include spear phishing, which represents targeted attacks directed at specific individuals or organizations and incorporates personalized information harvested from social media profiles or public records to substantially increase credibility and success rates. At the highest end of targeting precision, whaling describes high-value spear phishing attacks specifically targeting senior executives or key organizational decision-makers, often involving elaborate business email compromise scenarios where attackers impersonate organizational leadership to authorize fraudulent wire transfers or sensitive data access. Clone phishing represents a distinct and particularly effective variant in which attackers carefully replicate legitimate emails previously sent by trusted organizations, preserving all original structure and content while strategically replacing only the legitimate links or attachments with malicious ones, thereby leveraging recipients' prior familiarity with the original message to reduce skepticism.

Phishing campaigns further vary significantly in their attack objectives. Credential harvesting attacks are specifically designed to steal login credentials through fake authentication pages that meticulously mimic legitimate services, allowing attackers to harvest credentials for subsequent account compromise. Malware delivery attacks dispatch emails containing malicious attachments or links designed to install ransomware, spyware, banking trojans, or other malicious software on victim systems. Financial fraud attacks involve direct requests for wire transfers, gift card purchases, cryptocurrency transfers, or other immediate financial transactions, techniques particularly common in business email compromise scenarios targeting organizations. Finally, information gathering attacks serve reconnaissance purposes, designed to collect intelligence about targets, organizational structures, decision-making hierarchies, security practices, or employee relationships for use in subsequent, more sophisticated attacks.

Technical sophistication of phishing attacks exhibits substantial variation. Template-based attacks represent the simplest category, consisting of mass-produced attacks using standardized templates with minimal customization beyond recipient names or generic personalization. Modern attacks increasingly leverage artificial intelligence and large language models to generate contextually appropriate, grammatically flawless, and culturally adapted content that deliberately avoids linguistic markers and stylistic anomalies previously associated with phishing. At the most sophisticated end, multi-stage attacks involve complex, coordinated campaigns with multiple sequential touchpoints, extended reconnaissance phases, and progressive trust-building strategies before delivering the final malicious payload, often combining sophisticated social engineering with technical exploitation to maximize likelihood of success.

\subsection{Prevalence and Economic Impact}

According to the \ac{APWG}, phishing attacks experienced a notable decline in 2024, with approximately 3.7 million reported attacks representing a 24\% decrease from 2023 levels (Figure \ref{fig:phishing_trends}). However, this statistical reduction should not be interpreted as a comprehensive victory against phishing. Several factors complicate this apparent progress:

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/phishing_trends.png}
    \caption{Temporal trends in reported phishing attacks (2020-2024). Source: Anti-Phishing Working Group (APWG) quarterly reports.}
    \label{fig:phishing_trends}
\end{figure}

\textbf{Quality Over Quantity:} The decrease in volume may reflect a shift toward more sophisticated, targeted attacks that are less likely to be reported to aggregation services like PhishTank or APWG. Spear phishing and BEC attacks, which represent a growing proportion of total attacks, often go unreported due to organizational concerns about reputation damage or regulatory consequences.

\textbf{Detection Bias:} Improved detection systems may be catching more attacks before they reach end users, reducing the reported volume while the actual attack attempts remain constant or increase. This creates a paradoxical situation where better defenses obscure the true threat landscape.

\textbf{Reporting Gaps:} Many phishing attempts are never reported, particularly those targeting individuals rather than organizations. The APWG data represents only reported incidents, likely underestimating the true scale of the problem by a significant margin.

Despite the volumetric decline, the financial impact of phishing remains severe. According to the \ac{IC3} 2024 \ac{FBI} report, phishing-related losses in the United States alone totaled approximately USD 70 million in reported incidents \cite{IC32024}. This figure represents only direct, reported financial losses and excludes indirect costs such as remediation expenses, productivity losses, reputational damage, and the costs of data breach notification and legal proceedings. Industry estimates suggest that the true global cost of phishing, including all direct and indirect impacts, exceeds USD 10 billion annually.

Furthermore, phishing attacks frequently serve as the initial vector for more extensive data breaches. The 2023 Verizon Data Breach Investigations Report found that phishing was involved in 36\% of all data breaches, often providing attackers with the initial foothold needed to deploy ransomware, establish persistent access, or exfiltrate sensitive data. This amplification effect means that the true cost of phishing extends far beyond direct financial fraud.

\subsection{Evolution of Phishing Techniques}

Phishing attacks have evolved considerably since their emergence in the mid-1990s, reflecting an adaptive adversarial landscape where attackers continuously refine their approaches in response to defense mechanisms and user awareness improvements. Early attacks were characterized by poor grammar, obvious formatting issues, and easily identifiable technical indicators such as mismatched URLs, suspicious sender addresses, and crude HTML construction that made their malicious intent apparent to attentive users. Modern phishing campaigns, by contrast, employ sophisticated social engineering informed by deep knowledge of target organizations, leverage legitimately compromised accounts to enhance authenticity, and increasingly utilize artificial intelligence to generate convincing, contextually appropriate content that rivals authentic organizational communications in quality and persuasiveness.

This evolution reflects several distinct trends that characterize contemporary phishing operations. Increased personalization represents a primary evolutionary pressure shaping modern attacks, as attackers now routinely incorporate information harvested from social media, data breaches, and public records to create highly personalized messages that reference specific relationships, recent organizational activities, shared professional interests, or contextual information known to be true. This personalization significantly increases perceived credibility from the recipient's perspective and substantially improves likelihood of success compared to generic mass-mailed phishing that makes no attempt at customization.

Simultaneously, attackers have fundamentally shifted away from hosting phishing sites on obviously suspicious domains, a strategy that triggered security alerts and blacklist detection, toward legitimate infrastructure abuse at scale. Rather than registering malicious domains requiring registration payments and creating audit trails, attackers increasingly compromise legitimate websites through exploitation of outdated software, abuse cloud services with generous free tiers designed for development use, or exploit URL shorteners and redirectors to obscure malicious destinations behind trusted intermediaries. This approach allows attacks to bypass many traditional URL-based detection mechanisms that rely heavily on domain reputation scoring or centralized blacklist matching.

Modern phishing emails employ various sophisticated evasion techniques specifically designed to circumvent automated detection systems while remaining effective against human targets. These include time-delayed payload delivery that executes hours or days after initial access to avoid temporal correlation with delivery and filtering events, CAPTCHA challenges presented to human-like users while automatically blocking or providing degraded service to automated analysis systems, fingerprinting techniques that detect sandboxed or virtualized analysis environments and alter malicious behavior accordingly, and polymorphic content that varies across recipients to complicate signature-based detection approaches that rely on identifying identical malicious payloads across multiple messages.

The availability and rapidly increasing accessibility of large language models has fundamentally transformed the economics and logistics of phishing content generation. Rather than requiring skilled social engineers, experienced copywriters, or individuals with deep domain knowledge, attackers can now automatically generate grammatically flawless, contextually appropriate phishing content at massive scale using commodity tools. These \ac{AI}-generated emails demonstrate particular strength in adapting to different cultural contexts and linguistic settings, mimicking specific writing styles and organizational communication patterns accurately, and deliberately avoiding common linguistic markers and stylistic anomalies that traditional detection systems have learned to recognize through training on historical phishing examples, creating a significant challenge for systems reliant on lexical or stylistic anomaly detection.

\subsection{Defense Mechanisms and Current Limitations}

Email authentication protocols, including \acf{SPF}, \acf{DKIM}, and \acf{DMARC}, provide technical mechanisms for verifying sender domain authenticity and detecting spoofed messages that falsely claim to originate from particular domains \cite{DEROUET20165}. These protocols function by allowing domain administrators to cryptographically authorize mail servers and message signatures, enabling receiving servers to validate that messages actually originate from authorized sources. However, these authentication mechanisms face several significant practical limitations. They are not universally implemented across the global email infrastructure, many organizations have not yet deployed these protocols, allowing their domains to be spoofed with impunity. When implemented, they can be misconfigured in ways that fail to prevent abuse. Most significantly, they do not prevent attacks originating from legitimately compromised accounts, since compromised legitimate accounts produce messages that pass all authentication checks by definition. Furthermore, authentication protocols address only sender identity verification without evaluating message content, intent, emotional manipulation tactics, or likelihood of being malicious.

Transport security mechanisms, including \acf{MTA-STS} and \ac{TLS} reporting protocols, ensure secure message transmission between mail servers, preventing interception or tampering during transit between systems. While these mechanisms provide value by protecting message integrity and confidentiality during transmission, they do nothing to address phishing content that is transmitted legitimately between mail servers, as the authentication and encryption layers at the transport level remain completely agnostic to message intent, credibility, or whether the sender is impersonating another entity.

URL reputation systems, such as Google Safe Browsing and various commercial threat intelligence feeds, maintain continuously updated databases of known malicious URLs and block or flag access to identified phishing sites through browser integration or email gateway filtering. These systems are fundamentally reactive by nature, requiring that specific URLs be identified as malicious through reports from affected users, automated scanning, or security researchers before they can be blocked. This reactive posture creates an inherent window of vulnerability during which zero-day phishing sites remain active and dangerous, particularly in targeted campaigns where victim counts are small and unlikely to trigger community-based detection systems.

Traditional content filtering approaches, including spam filters and rule-based detection systems, analyze message content for suspicious patterns, keywords, suspicious vocabulary, or structural characteristics that have historically correlated with phishing in training data. While such approaches achieved reasonable performance against early generation phishing attacks utilizing crude language and obvious red flags, they struggle substantially with sophisticated attacks that deliberately avoid common triggers through careful word choice, strategic synonym substitution, structural variation, and content crafting deliberately informed by knowledge of the specific detection rules in operational use.

The limitations of these traditional defenses have driven significant research interest in machine learning and deep learning approaches that can identify phishing attempts based on learned patterns rather than explicit rules, and that can potentially detect novel attacks that have not been previously observed.

\section{Machine Learning and Deep Learning Approaches to Phishing Detection}

\subsection{First Generation: Rule-Based and Blacklist Systems}

The earliest automated phishing detection systems relied primarily on manually curated rules and blacklists. These systems operated on simple pattern matching: emails were flagged if they originated from known malicious domains, contained specific keywords associated with phishing (e.g., "verify your account," "urgent action required"), or exhibited obvious technical anomalies such as mismatched sender addresses or suspicious URL patterns.

While straightforward to implement and interpret, rule-based systems suffered from fundamental limitations that rendered them increasingly ineffective against evolving threats \cite{abu2007survey}. First, their reactive nature meant that rules could only detect attacks matching known patterns, providing no protection against novel techniques or zero-day campaigns. Second, these systems exhibited brittleness, as attackers could easily circumvent detection through minor modifications such as alternative spellings, synonym substitution, or slight changes in URL structure. Third, the maintenance burden proved substantial, with each new attack variant requiring manual rule creation, a process that could not keep pace with the volume and velocity of emerging threats. Finally, overly broad rules frequently generated false positives, flagging legitimate emails containing similar keywords or patterns, particularly in domains like finance or IT where security-related communication is routine.

The fundamental problem with rule-based approaches is their inability to generalize beyond explicitly programmed patterns. As attack sophistication increased, the limitations of this paradigm became insurmountable, necessitating more adaptive approaches.

\subsection{Second Generation: Classical Machine Learning with Engineered Features}

Recognition of these limitations led to the adoption of supervised machine learning approaches in the mid-2000s. Rather than manually encoding detection rules, researchers began extracting numerical features from emails and training statistical classifiers to distinguish phishing from legitimate messages \cite{khonji2013phishing}.

Typical feature engineering for phishing detection involved extracting and quantifying various aspects of email structure and content. Header-based features included sender domain reputation and age, presence and validity of \ac{SPF}, \ac{DKIM}, and \ac{DMARC} authentication, routing path complexity and geographic anomalies, temporal features such as send time and time zone consistency, and sender-recipient relationship indicators. Content-based features encompassed lexical statistics including vocabulary richness and word length distributions, \ac{TF-IDF} vectors capturing keyword importance, bag-of-words representations, presence of urgency or fear-inducing keywords, grammatical complexity measures, and HTML-to-text ratios. URL-based features examined domain age and registration information, use of IP addresses instead of domain names, URL length and complexity, presence of URL shorteners or redirectors, and domain similarity to legitimate brands for typosquatting detection. Structural features analyzed HTML structure complexity, image-to-text ratios, form presence and characteristics, JavaScript usage patterns, and embedded object counts.

These engineered features were fed into classical machine learning classifiers including Support Vector Machines (\acs{SVM}), Random Forests, Naive Bayes, Logistic Regression, and various ensemble methods \cite{almomani2013survey}. This generation of systems achieved substantial improvements over rule-based approaches in several key areas. Trained classifiers demonstrated improved generalization, recognizing phishing patterns in emails that didn't exactly match training examples and thus providing some ability to detect novel attacks. They also exhibited adaptability, as models could be retrained on new data, allowing systems to evolve with emerging threats without requiring manual rule updates. Furthermore, \ac{ML} approaches enabled quantifiable performance assessment through systematic evaluation using metrics like precision, recall, and F1-score on held-out test sets.

However, second-generation systems faced their own significant limitations. The feature engineering bottleneck meant that detection quality was fundamentally constrained by the quality of manually engineered features, with effective feature creation requiring deep domain expertise and proving time-consuming and labor-intensive. Feature brittleness presented another challenge, as engineered features that worked well on training data often failed to generalize to new attack vectors, for example, URL-based features became less effective when attackers used compromised legitimate domains. Manual feature engineering inevitably missed subtle patterns or complex interactions that might indicate phishing but weren't obvious to human analysts. Finally, traditional features captured only surface-level characteristics and struggled to understand semantic meaning, context, or intent, precisely the dimensions that sophisticated social engineering attacks exploit.

Despite these limitations, classical \ac{ML} approaches with engineered features remained state-of-the-art for over a decade and continue to be deployed in many production systems due to their computational efficiency, interpretability, and respectable performance on traditional phishing attacks.

\subsection{Third Generation: Early Deep Learning Approaches}

The deep learning revolution of the 2010s introduced neural network architectures capable of automatically learning feature representations from raw data, potentially eliminating the feature engineering bottleneck. Researchers began applying Convolutional Neural Networks (\acp{CNN}), Recurrent Neural Networks (\acp{RNN}), and Long Short-Term Memory (\acs{LSTM}) networks to phishing detection \cite{fang2020deep}.

\acp{CNN} were employed to identify spatial patterns in email structure, treating HTML or text as quasi-image data where local patterns (specific phrase combinations, HTML structures) could be detected through convolutional filters. \acp{RNN} and \acp{LSTM} were applied to capture sequential dependencies in email text, enabling the model to understand how meaning evolves throughout a message and to detect manipulation tactics that span multiple sentences or sections.

These early deep learning approaches demonstrated several theoretical advantages. Networks learned relevant representations directly from data without requiring manual feature specification, providing automated feature learning capabilities. Deep architectures learned multiple levels of abstraction, from low-level lexical patterns to high-level semantic concepts, creating hierarchical representations of email content. Additionally, deep networks could model complex, non-linear relationships between features and outcomes through their non-linear decision boundaries.

However, in practice, early deep learning approaches often failed to outperform well-engineered classical ML systems, particularly when deployed on phishing detection tasks \cite{basnet2008detection}. Several factors contributed to this underwhelming performance. Data scarcity proved problematic, as deep learning requires large training datasets, but high-quality labeled phishing email corpora were (and remain) limited, models frequently overfitted to small training sets, memorizing specific examples rather than learning generalizable patterns. Real-world email traffic exhibits severe class imbalance, with legitimate emails vastly outnumbering phishing attempts, and training deep networks on imbalanced data is challenging and often results in models biased toward the majority class. The computational cost of training and deploying deep neural networks required substantially more resources than classical approaches, making them impractical for real-time filtering of high-volume email streams. The "black box" nature of deep neural networks made it difficult for security analysts to understand why specific emails were classified as phishing, limiting trust and adoption in security-critical applications. Finally, deep networks proved susceptible to adversarial examples, carefully crafted inputs designed to fool the model, raising concerns about deployment in adversarial environments where attackers actively seek to evade detection.

These challenges meant that despite significant research interest, third-generation deep learning approaches struggled to achieve widespread practical deployment, and many production systems continued to rely on classical ML with engineered features or hybrid approaches combining both paradigms.

\subsection{Fourth Generation: Transformer-Based Architectures and Transfer Learning}

The development of transformer architectures and the paradigm of transfer learning through large-scale pretraining has fundamentally changed the landscape of phishing detection, finally delivering on the promise of deep learning for this domain \cite{vaswani2017attention}.

Transformers, introduced by Vaswani et al. in their seminal "Attention is All You Need" paper, represent a radical departure from previous neural architectures \cite{vaswani2017attention}. Rather than processing text sequentially (as \acp{RNN} do) or through local windows (as \acp{CNN} do), transformers employ self-attention mechanisms that allow each word or token in a sequence to directly attend to every other word, regardless of distance. This architecture provides several critical advantages for phishing detection. First, transformers excel at capturing long-range dependencies, phishing emails often employ manipulation tactics that span the entire message, such as establishing urgency in the subject line, building credibility in opening paragraphs, and delivering the malicious request near the end. Transformers can capture these dependencies without the vanishing gradient problems that plague \acp{RNN}. Second, the self-attention mechanism enables transformers to understand how the meaning of a word or phrase depends on its context throughout the entire email, which is crucial for detecting subtle manipulation where individually innocuous elements combine to create a suspicious pattern. Third, unlike sequential \acp{RNN}, transformers process all tokens simultaneously, enabling efficient training on modern hardware accelerators.

The true breakthrough came not from the transformer architecture alone, but from the transfer learning paradigm enabled by large-scale pretraining. Models like \ac{BERT} (Bidirectional Encoder Representations from Transformers), \ac{RoBERTa} (A Robustly Optimized BERT Pretraining Approach), and \ac{DistilBERT} (a distilled, smaller version of BERT) are pretrained on massive text corpora (billions of words from books, Wikipedia, web crawls) to learn general language understanding before being fine-tuned on specific downstream tasks like phishing detection.

\textbf{BERT:} Introduced by Devlin et al. in 2018, BERT revolutionized natural language processing through its bidirectional training approach \cite{devlin2018bert}. Unlike previous models that processed text left-to-right or right-to-left, BERT analyzes context from both directions simultaneously. During pretraining, BERT learns to predict randomly masked tokens based on bidirectional context (the "masked language modeling" objective), developing robust representations of language structure and meaning. For phishing detection, this bidirectional understanding is particularly valuable: BERT can recognize when urgent language in one part of an email is inconsistent with the claimed sender identity in another part, or when a seemingly legitimate request is undermined by subtle inconsistencies in tone or phrasing throughout the message.

\textbf{RoBERTa:} Liu et al.'s RoBERTa improves upon BERT through more rigorous pretraining methodology \cite{liu2019roberta}. Key modifications include: training on ten times more data (160GB of text vs. 16GB), longer training duration with larger batch sizes, removal of the next-sentence-prediction pretraining task (which BERT included but RoBERTa authors found unhelpful), dynamic masking patterns that change across epochs rather than static masks determined during preprocessing, and training on longer sequences. These improvements result in embeddings that capture more nuanced linguistic patterns, particularly beneficial for detecting sophisticated phishing that employs subtle social engineering rather than obvious red flags.

\textbf{DistilBERT:} Recognizing that BERT's size (110M parameters) limits deployment in resource-constrained environments, Sanh et al. developed DistilBERT through knowledge distillation \cite{sanh2019distilbert}. This process trains a smaller "student" model to mimic a larger "teacher" model's behavior, resulting in a model that is 40\% smaller, 60\% faster, and retains 97\% of BERT's language understanding capability. For phishing detection systems that must process email streams in real-time with limited computational resources, DistilBERT offers an attractive balance between performance and efficiency.

When fine-tuned for phishing detection, transformer-based models have achieved unprecedented performance levels. These models effectively encode email bodies, subject lines, and HTML structure into dense vector embeddings that capture semantic and contextual signals far beyond simple lexical overlap \cite{uddin2025}.

Recent studies demonstrate the superiority of transformer approaches. Lee et al. achieved F1-scores exceeding 98\% on benchmark phishing datasets using fine-tuned \ac{BERT} variants with attention mechanisms specifically adapted for security applications \cite{lee2022transformer}. Zhang et al. demonstrated that transformer-based models maintain high accuracy on zero-day phishing attacks, campaigns employing novel social engineering tactics not seen during training, significantly outperforming classical \ac{ML} approaches that rely on memorized patterns \cite{zhang2023zero}. Uddin et al. showed that explainable transformer architectures can not only detect phishing with high accuracy but also provide interpretable attention weights indicating which parts of an email most strongly influenced the classification decision, addressing the interpretability concerns that limited adoption of earlier deep learning approaches \cite{uddin2025}.

The learned embeddings from these models prove valuable not only for binary classification but also for downstream security applications such as phishing campaign clustering (identifying coordinated attacks from the same threat actor), semantic similarity search (finding related phishing emails in historical databases), and attack attribution.

\subsection{Multi-Modal Integration and Ensemble Approaches}


Recognition that phishing attacks exploit multiple vectors simultaneously has motivated research into multi-modal detection systems that integrate diverse information sources \cite{PATRA2025110403, electronics12204261}. Modern phishing detection increasingly combines several approaches. Textual content analysis leverages transformer embeddings of the email body, subject line, and text extracted from HTML, capturing semantic meaning and emotional tone. Header metadata analysis considers authentication results (\ac{SPF}, \ac{DKIM}, \ac{DMARC}), routing path analysis, temporal features, sender-recipient relationship indicators, and domain reputation signals. URL analysis uses specialized encoders for URLs, capturing lexical features such as length, special character usage, and subdomain depth, as well as reputation signals from threat intelligence feeds and domain registration information. HTML structure analysis examines features describing page complexity, image-to-text ratios, form presence and characteristics, JavaScript usage patterns, and iframe embedding, which can indicate attempts to obscure content or mimic legitimate sites. Attachment analysis evaluates file type distributions, entropy measures indicating potential encryption or packing, and, in some systems, results from sandboxed execution or static malware analysis.

Ensemble methods that combine predictions from multiple specialized models have shown particular promise \cite{park2023ensemble}. For instance, an ensemble might include a URL-based classifier, a content-based transformer model, a header analysis module, and an attachment screening component, with predictions combined through weighted voting, stacking, or meta-learning approaches. This multi-modal integration addresses a critical limitation of single-feature systems: sophisticated attackers can often evade detection systems that rely on a single signal, such as using legitimate compromised domains to bypass URL blacklists, or carefully crafted content to evade text analysis, but struggle to simultaneously evade all detection modalities \cite{kim2023multimodal}.

\subsection{Vector Similarity and Semantic Search Approaches}


An alternative detection paradigm involves converting emails into high-dimensional vector representations using transformer embeddings, then using similarity search to identify emails semantically similar to known phishing examples \cite{mikolov2013distributed}. This approach enables several capabilities, including few-shot detection, where phishing campaigns are identified based on similarity to a small number of examples, which is particularly useful when labeled training data for a new attack type is scarce. It also supports campaign clustering, allowing automatic grouping of related phishing emails to identify coordinated attacks, track campaign evolution, and potentially attribute attacks to specific threat actors. Additionally, anomaly detection is possible by flagging emails that are semantically dissimilar from typical legitimate correspondence patterns for a given user or organization.

While vector similarity approaches have shown promise, they have generally been outperformed by fine-tuned transformer classifiers on benchmark datasets \cite{PATRA2025110403}. However, they remain valuable as complementary techniques in production systems, particularly for identifying emerging campaign clusters and for cases where real-time classification latency is critical.

\subsection{Adversarial Machine Learning and Robustness}


As \ac{ML}-based detection becomes more prevalent, a critical concern has emerged: adversarial attacks specifically designed to evade learned models. Adversarial machine learning research in phishing detection examines how attackers might craft emails that fool classifiers while remaining effective at deceiving human targets \cite{grosse2017adversarial}.

Several adversarial techniques have been demonstrated, including evasion attacks, which involve modifying phishing emails to evade detection while preserving their effectiveness. This might include synonym substitution to alter text while maintaining meaning, strategic insertion of benign-appearing content to dilute malicious signals, careful HTML obfuscation that renders differently in email clients compared to automated analyzers, or polymorphic generation of attack variants that differ sufficiently to evade signature-based components. Poisoning attacks are another technique, where attackers influence training data, for example through feedback mechanisms where users report false positives, injecting mislabeled examples designed to corrupt the learned model. This is particularly concerning for online learning systems that continually update models based on user feedback. Model extraction is also a risk, as attackers may query a detection system repeatedly with variations of phishing content to reverse-engineer the model's decision boundary, then craft attacks specifically designed to fall on the legitimate side of that boundary.

Defensive mechanisms against adversarial attacks include adversarial training, which involves training models on a mixture of legitimate examples, real phishing samples, and adversarially-modified versions of both, forcing the model to learn robust decision boundaries \cite{goodfellow2014explaining}. Defensive distillation uses knowledge distillation to create models with smoother decision surfaces that are less sensitive to small input perturbations \cite{papernot2016distillation}. Ensemble diversity, achieved by combining multiple models trained on different feature sets or with different architectures, makes it difficult for attackers to craft examples that evade all ensemble members simultaneously. Input preprocessing, such as paraphrasing, normalization, or feature discretization, preserves semantic meaning but removes adversarial perturbations.

However, adversarial robustness remains an active research area with no perfect solutions. The fundamental challenge is that effective phishing requires fooling humans, which inherently means the content must appear legitimate at some level, creating an inevitable trade-off between detection sensitivity and false positive rates.

\section{Sentiment Analysis and Emotional Manipulation in Phishing}

While the majority of phishing detection research focuses on technical and structural features, sentiment analysis, the computational study of opinions, emotions, and attitudes expressed in text, represents a significant but underexplored dimension \cite{pang2008opinion}. This gap is particularly notable given that emotional manipulation constitutes the fundamental mechanism through which phishing attacks succeed.

\subsection{Psychological Foundations of Phishing}

Phishing attacks fundamentally exploit human psychology rather than technical vulnerabilities. Even technically sophisticated users can fall victim to well-crafted phishing emails that trigger emotional responses that bypass rational decision-making processes.

\subsubsection{Cognitive Biases and Dual-Process Theory}

Kahneman's dual-process theory posits that human cognition operates through two systems: System 1, which is fast, automatic, and emotion-driven, and System 2, which is slow, deliberate, and analytical \cite{kahneman2011thinking}. Phishing attacks are designed to engage System 1 processing, triggering immediate emotional responses that prompt action before System 2 can critically evaluate the request. For example, an email claiming "Your account will be suspended in 24 hours unless you verify your credentials" triggers fear and urgency, prompting immediate System 1 response rather than the slower, more critical System 2 evaluation that might recognize inconsistencies or suspicious elements.

\subsubsection{Cialdini's Principles of Persuasion}

Robert Cialdini identified six universal principles of persuasion that influence human behavior across cultural contexts, all of which are routinely and strategically exploited in phishing attacks to enhance their effectiveness \cite{cialdini2021influence}. The principle of reciprocity describes the tendency to feel obligated to return favors or compensate others for benefits received, and phishing emails routinely leverage this principle by offering something of apparent value, a free gift, exclusive information, lottery winnings, before requesting the sensitive information desired by attackers, creating a sense of obligation to reciprocate. Commitment and consistency refer to people's tendency to follow through on commitments once made, and phishing attacks exploit this by referencing previous interactions (whether real or fabricated) to create expectations that recipients should behave consistently with prior commitments or patterns. Social proof describes people's tendency to look to others' behavior to guide their own actions, and phishing emails commonly claim "thousands of users have already updated their information" or fabricate testimonials from satisfied customers to create false social validation implying that the requested action is normal and safe. Authority describes the deep conditioning of individuals to obey authority figures, and phishing attacks deliberately impersonate organizational executives, IT departments, government agencies, or other trusted brands to leverage this principle and compel compliance. Liking describes the tendency of people to be more likely to say yes to requests from those they like, and phishing attacks targeting specific individuals often reference shared interests, mutual connections, or common group memberships to build perceived rapport and likability. Finally, scarcity refers to the principle that limited availability increases perceived value, and phishing emails frequently employ claims such as "this offer expires in 24 hours" or "only 3 spots remaining" to create artificial urgency and scarcity-driven pressure.

\subsection{Emotional Triggers in Phishing Campaigns}

Research in social psychology and behavioral security has identified several primary emotional states that phishing attacks strategically exploit to bypass rational decision-making processes and compel victim action. Understanding these emotional vectors is essential for effective detection, as they manifest in specific emotional tones, linguistic patterns, and rhetorical structures that sentiment analysis can potentially identify and characterize.

The primary emotional category exploited across numerous phishing campaigns involves fear and urgency, with messages deliberately creating artificial time pressure or threatening negative consequences to bypass deliberation. Examples include claims that an account will be suspended within a specified timeframe, security breaches allegedly requiring immediate password changes to prevent unauthorized access, legal consequences threatened for alleged violations of regulations, or package delivery failures requiring urgent recipient action. These attacks deliberately leverage the psychological principle of loss aversion established through decades of behavioral research, which demonstrates that potential losses psychologically loom substantially larger than equivalent gains in human decision-making, making threats of account closure, data loss, or regulatory consequence particularly effective at triggering immediate action despite minimal verification \cite{wash2020understanding}.

A second major category of emotional exploitation involves greed and opportunity, where carefully crafted appeals to financial gain bypass critical thinking through the promise of substantial financial reward. Common variants include lottery winnings notifications for contests the recipient never entered, inheritance notifications from unknown distant relatives, investment opportunities with guaranteed returns that defy economic logic, and exclusive limited-time offers allegedly available only to the recipient based on special status. These attacks deliberately exploit optimism bias, the tendency to overestimate positive outcomes, and the availability heuristic, cognitive phenomena that cause recipients to focus attention on potential gains rather than critically evaluating the true likelihood of the scenario \cite{modic2011willing}.

Authority and trust represent a third exploitation vector, where attackers carefully impersonate trusted institutions, organizational executives, government agencies, or technical support personnel to leverage existing trust relationships and recipients' ingrained deference to authority figures. Business email compromise attacks frequently impersonate CEOs or CFOs requesting urgent wire transfers to supposedly time-sensitive business opportunities, exploiting both authority bias and deep organizational hierarchy norms that condition employees to comply with executive requests. IT support impersonation similarly leverages users' tendency to defer to technical authority figures and their reluctance to question individuals claiming specialized technical knowledge \cite{krombholz2015advanced}.

Curiosity and social validation constitute a fourth emotional driver that phishing attacks routinely exploit. Messages leverage natural human curiosity or the desire for social connection, group belonging, and fear of missing out from social interactions. Examples include mysterious messages phrased as "You won't believe what I found about you online" designed to trigger curiosity, or fake social media notifications about tags, messages, friend requests, or shares. These attacks exploit deep psychological drives, the human need for social belonging and fear of missing out from group activities and information, psychological drivers that are particularly potent in social media contexts where such notifications are typically legitimate \cite{butavicius2016panning}.

Finally, guilt and obligation represent a fifth emotional manipulation strategy, where attackers deliberately engineer feelings of personal responsibility or moral obligation in target victims. Tactics include fake charity appeals claiming funds are urgently needed for worthy causes, fabricated late payment notices implying financial delinquency or default, or claims that user verification action is necessary to help prevent fraud affecting other customers. These appeals deliberately exploit prosocial instincts and individuals' deep desire to avoid being perceived as selfish, negligent, or unhelpful toward those in need.

\subsection{Current State of Sentiment-Based Detection}

Despite the centrality of emotional manipulation to phishing success, sentiment analysis has received limited attention in the phishing detection literature. When sentiment or emotional tone has been considered, it has typically been treated as an auxiliary signal rather than a primary detection feature.

\subsubsection{Limitations of Traditional Sentiment Approaches}


Early attempts to incorporate sentiment analysis into phishing detection relied on lexicon-based or rule-based methods that proved insufficient for capturing the nuanced emotional manipulation employed by sophisticated attackers \cite{liu2012sentiment}. These approaches included keyword counting, which involved simple frequency counts of urgency-related words, such as "urgent," "immediately," or "expires," and fear-inducing terms like "suspended," "violation," or "unauthorized." While straightforward, these methods suffered from high false positive rates, as legitimate emails, particularly from IT security teams, financial institutions, or customer service departments, often contain similar language. Moreover, sophisticated attackers learned to evade keyword-based detection through synonym substitution or more subtle emotional manipulation.

Lexical heuristics were also used, relying on surface-level features such as exclamation mark frequency, capitalization patterns, or imperative mood verb counts. Although these features correlated with phishing in early studies, attackers adapted their writing styles, and many legitimate marketing or internal communications also exhibit these characteristics.

Dictionary-based sentiment scoring approaches utilized sentiment lexicons like AFINN or SentiWordNet to assign valence scores, positive or negative, to emails. However, these methods captured only crude sentiment polarity and failed to recognize the strategic emotional manipulation characteristic of phishing, such as the combination of positive framing, for example "You've won!", with urgency tactics, like "Claim your prize within 24 hours," that creates psychological pressure.

The fundamental limitation of these traditional approaches is their inability to understand context, recognize subtle emotional manipulation strategies, and distinguish between legitimate emotionally-toned communication and manipulative phishing attempts.

\subsubsection{Recent Advances in Sentiment-Aware Detection}

The development of transformer-based language models has enabled more sophisticated sentiment analysis that captures nuanced emotional cues. Recent work has begun to demonstrate the potential of sentiment-aware detection:

Salian (2024) employed \ac{DistilBERT} to extract embeddings capturing sentiment and emotional tone, which were then fed into a classical \ac{SVM} classifier \cite{salian2024enhancing}. This hybrid approach was compared against a baseline \ac{SVM} using only traditional engineered features. The sentiment-aware model achieved 97\% F1-score compared to 94\% for the baseline, a 3 percentage point improvement. While this gain might appear modest, it represents a significant advance considering the already high baseline performance. More importantly, the improvement was most pronounced on sophisticated phishing attacks that employed subtle emotional manipulation rather than obvious red flags, suggesting that sentiment analysis provides complementary information to traditional features.

Melndez et al. (2024), in their comparative investigation of traditional machine learning and transformer models for phishing detection, explicitly noted that results could be "further improved by incorporating sentiment analysis techniques to detect social-engineering tactics and to better understand the emotional tone and intent behind the email content" \cite{electronics13244877}. This observation from a comprehensive empirical study underscores the recognition that sentiment represents an underutilized dimension in current detection systems.

Abdelhamid et al. (2022) developed an emotion-aware phishing detection system that moves beyond simple positive/negative sentiment to identify specific emotional manipulation patterns \cite{abdelhamid2022emotion}. Their multi-dimensional emotion analysis framework distinguishes between fear-based appeals, excitement-based manipulation, guilt-induction, and authority-leveraging tactics. This fine-grained emotional categorization enables more targeted detection and provides security analysts with insights into the psychological tactics employed by specific campaigns.

\subsection{The Potential of Fine-Grained Emotion Analysis}


Recent research in affective computing suggests that moving beyond binary positive or negative sentiment to multi-dimensional emotion analysis may significantly improve phishing detection. Rather than simply classifying emails as expressing positive or negative sentiment, fine-grained approaches can identify specific emotions based on established psychological models. For example, Ekman's basic emotions include fear, anger, disgust, surprise, happiness, and sadness \cite{ekman1992argument}. Phishing emails often combine multiple emotions strategically, such as surprise, for instance "You've won!", followed by urgency or fear, like "Claim within 24 hours or forfeit." Plutchik's emotion wheel provides a more nuanced model, including eight primary emotions and their combinations \cite{plutchik2001nature}, which can capture complex emotional manipulation, such as anticipation combined with trust, commonly seen in business email compromise scenarios. Dimensional models represent emotions along continuous dimensions like valence (pleasant or unpleasant), arousal (high or low energy), and dominance (in control or submissive). Phishing emails often exhibit specific patterns in this space, such as high arousal, indicating urgency, combined with negative valence, representing threats, and low dominance, implying the recipient must respond to external demands.

Mohammad and Turney's work on emotion lexicons and crowdsourced emotion annotation provides practical tools for implementing fine-grained emotion analysis \cite{mohammad2013crowdsourcing}. Their research demonstrates that humans can reliably identify specific emotions in text, and that these annotations can train models to automatically recognize emotional manipulation patterns.

Fine-grained emotion analysis offers several advantages for phishing detection. It enables strategic pattern recognition by identifying specific combinations of emotions characteristic of different phishing strategies, such as fear combined with urgency in account suspension scams versus excitement combined with greed in lottery scams. The approach facilitates context-appropriate baselines, enabling systems to learn what emotional tone is appropriate for different types of legitimate communication, such as marketing emails that appropriately express excitement or security notifications that appropriately express concern, and flag deviations from these norms. Fine-grained analysis also supports user education by providing users with specific feedback about the emotional manipulation tactics employed in detected phishing, potentially improving security awareness and resilience. Finally, it aids in campaign attribution, as different threat actors often have characteristic emotional manipulation styles, enabling campaigns to be clustered and potentially attributed based on their emotional profiles.

\subsection{Critical Challenges and Research Gaps}


Despite growing recognition of sentiment analysis's potential, several significant challenges impede progress. One major challenge is dataset limitations, as most existing phishing datasets lack fine-grained emotional annotations \cite{abu2018phishing}. While researchers have access to large corpora of labeled phishing versus legitimate emails, very few datasets include annotations describing the specific emotional manipulation tactics employed, and this lack of labeled data directly limits the development of sophisticated sentiment-aware detection systems. Another challenge is cultural and linguistic variation, since emotional expression varies significantly across cultures and languages \cite{mohammad2016sentiment}. Emotional manipulation tactics that work in English-speaking contexts may not translate directly to other linguistic and cultural settings, so developing globally applicable sentiment-aware detection systems requires culturally-adapted emotion models and diverse multilingual training data. Adversarial adaptation is also a concern, as sentiment-based detection becomes more prevalent, attackers will adapt their emotional manipulation strategies to evade detection \cite{biggio2018wild}. This creates an adversarial co-evolution dynamic where detection improvements drive attacker adaptation, necessitating continuous model updates and monitoring for emerging emotional manipulation tactics. Contextual complexity further complicates detection, since the same emotional content may be legitimate in one context but suspicious in another \cite{felt2017rethinking}. For example, urgency is appropriate in genuine time-sensitive communications from banks or service providers but suspicious in unsolicited messages, and marketing emails legitimately express excitement about products, but excessive excitement in purported official communications from government agencies should raise suspicion. Effective sentiment-based detection must account for these contextual factors. Finally, evaluation methodology presents a challenge, as standard evaluation metrics such as precision, recall, and F1 may not adequately capture the value of sentiment analysis for phishing detection. Sentiment features might provide the most value precisely for the most sophisticated attacks that are hardest to detect with traditional methods, but these attacks may constitute a small fraction of test sets, obscuring sentiment's contribution in aggregate metrics.

The recognition of these challenges motivates the need for new research specifically focused on emotional manipulation in phishing, including the creation of appropriately annotated datasets that can enable more sophisticated sentiment-aware detection approaches. As Sun et al. note, "fine-grained sentiment classification using \ac{BERT}" and similar advanced techniques requires datasets with detailed emotional annotations, not just binary phishing or legitimate labels \cite{sun2019fine}.

\section{Datasets for Phishing Detection}

The effectiveness of machine learning-based phishing detection systems is fundamentally constrained by the quality, diversity, and representativeness of available training datasets. This section examines the evolution of phishing datasets, from early legacy corpora to modern synthetic generation approaches, while identifying critical gaps that continue to challenge the field.

\subsection{Historical and Legacy Datasets}

\subsubsection{Early Foundational Corpora}

The earliest phishing detection research relied heavily on datasets that were not originally designed for security applications but were repurposed due to the lack of alternatives. The Enron E-mail Corpus (2004), released during litigation following Enron's collapse, contains approximately 500,000 emails from Enron executives and employees \cite{klimt2004enron}. While invaluable as a source of genuine business correspondence and widely used to establish baseline patterns of legitimate email communication, the Enron corpus has significant limitations for contemporary phishing research. Its corporate-centric language patterns, hierarchical communication structures, and 2000-2002 temporal frame do not reflect modern email usage, particularly in consumer or cross-organizational contexts. Moreover, it contains no phishing samples, limiting its utility to serving as a source of legitimate email baselines. Zhou et al. documented additional concerns about data quality, noting that organizational email corpora require careful preprocessing to remove duplicates, automatically generated messages, and other artifacts that might bias downstream analysis \cite{zhou2007strategies}.

Another example is the SpamAssassin Public Corpus (2002), one of the earliest publicly available email datasets, containing approximately 6,000 emails labeled as spam or legitimate ("ham") \cite{metsis2006spam}. While historically important for spam filtering research, this corpus predates modern phishing techniques and contains primarily traditional spam, such as advertising and scams, rather than the sophisticated social engineering attacks that characterize contemporary phishing. Its small size and age limit its relevance for current research.

Jose Nazario's Phishing Corpus (2006) is another notable dataset, consisting of approximately 2,000 phishing emails \cite{nazario2006phishing}. Despite its historical significance in establishing phishing as a distinct research area, the corpus is severely outdated. The attacks it contains reflect 2004-2006 era techniques, including crude spoofing attempts, poor grammar and spelling, and obvious URL manipulation, which bear little resemblance to modern \ac{AI}-assisted, socially-engineered phishing campaigns.

These legacy datasets established important precedents for corpus-based security research, but they suffer from limited scale, narrow attack vector coverage, and temporal obsolescence. Their continued citation in recent literature often reflects the scarcity of alternatives rather than their current utility.

\subsection{Community-Driven and Collaborative Initiatives}

Recognition of legacy datasets' limitations motivated the development of community-driven efforts to continuously collect and share phishing data:


\subsection{Modern Curated and Large-Scale Datasets}

Recognition that existing datasets inadequately represented modern phishing diversity has motivated recent efforts to compile comprehensive, large-scale corpora:


\subsection{Synthetic and Augmented Dataset Generation}

The challenges of collecting, annotating, and distributing real phishing emails have motivated increasing interest in synthetic data generation:

\subsubsection{Motivation for Synthetic Generation}

Synthetic phishing email generation addresses several critical challenges that limit traditional dataset collection approaches \cite{wang2023synthetic}:


\subsubsection{\ac{LLM}-Based Synthetic Generation}

The availability of large language models like GPT-3/GPT-4, Claude, and open-source alternatives has enabled sophisticated synthetic phishing generation:

Caripoti (2024) created a dataset of over 10,000 phishing and legitimate email samples, categorized by attack type (malware delivery, credential harvesting, business email compromise), and demonstrated that models trained on synthetic data could achieve comparable performance to those trained on real data \cite{caripoti2024synthetic}. Importantly, mixing synthetic and real training data improved robustness, suggesting that synthetic examples help models generalize by exposing them to variation not present in limited real-world collections.

Brown et al.'s work on few-shot learning with large language models demonstrated that modern \acp{LLM} can generate highly realistic text matching specified styles, tones, and content patterns with minimal examples \cite{brown2020language}. This capability enables generation of phishing emails that mimic specific organizational communication styles, individual writing patterns (for spear phishing), or cultural and linguistic contexts.

\subsubsection{Challenges and Limitations of Synthetic Data}


\subsection{Dataset Quality Dimensions and Evaluation}

The proliferation of diverse datasets has highlighted the need for standardized quality assessment frameworks. Stringhini et al.'s work on social network spam detection emphasized that dataset quality is multidimensional and cannot be assessed by scale alone \cite{stringhini2010detecting}. Key quality dimensions for phishing datasets include:

\subsubsection{Temporal Validity}

The extent to which datasets reflect current phishing tactics, language patterns, and target brands \cite{abu2018temporal}. Temporal validity degrades over time as attack techniques evolve, necessitating regular dataset updates or synthetic augmentation to maintain relevance. Abu-Salma et al.'s temporal analysis of phishing campaigns demonstrated significant evolution in tactics over even 2-3 year periods, suggesting that datasets more than five years old have questionable contemporary validity.

\subsubsection{Attack Vector Coverage}

Comprehensive representation of different phishing strategies: bulk phishing vs. spear phishing, credential harvesting vs. malware delivery vs. business email compromise, email-based vs. SMS vs. social media phishing \cite{ho2017detecting}. Ho et al.'s work on business email compromise detection highlighted that BEC attacks, despite representing a small fraction of total phishing volume, account for disproportionate financial losses and require different detection approaches than traditional credential phishing.

\subsubsection{Linguistic and Cultural Diversity}

Inclusion of multiple languages, cultural contexts, and communication styles to ensure global applicability \cite{ramanathan2018cross}. Ramanathan et al.'s research on cross-lingual phishing demonstrated that models trained primarily on English phishing often perform poorly on non-English attacks, and that emotional manipulation tactics vary significantly across cultural contexts.

\subsubsection{Label Quality and Annotation Consistency}

Standardized labeling schemes that enable cross-dataset comparison and meta-learning approaches \cite{merton2020annotation}. Merton et al. proposed annotation guidelines for phishing datasets, emphasizing the need for clearly defined labeling criteria, multiple annotators to assess inter-rater reliability, and documentation of edge cases and ambiguous examples. The authors noted that binary phishing/legitimate labels are insufficient for training sophisticated detection systems; datasets should include fine-grained annotations describing attack vector, social engineering tactics, emotional manipulation strategies, and technical indicators.

\subsubsection{Realistic Imbalance and Representativeness}

While academic datasets often strive for class balance (50\% phishing, 50\% legitimate) to facilitate machine learning, this does not reflect operational reality where phishing represents 1-5\% of total email volume. Oest et al.'s work on PhishFarm emphasized that detection systems should be evaluated on realistically imbalanced data to accurately assess operational performance, particularly false positive rates that become critical at scale \cite{oest2020phishfarm}.


\subsection{Critical Gaps and Research Needs}

Despite significant progress in dataset development, several critical gaps continue to impede research. One of the most prominent is the lack of fine-grained emotion and sentiment annotations. As established in Section 2.4, most existing phishing datasets lack detailed emotional annotations \cite{abdelhamid2022emotion}. While datasets may include binary phishing or legitimate labels and sometimes attack type categorizations, they rarely provide detailed annotations of emotional manipulation tactics, such as the specific emotions being exploited (fear, greed, curiosity), psychological persuasion principles employed (authority, urgency, social proof), or the intensity of emotional appeals.

This gap directly limits the development of sentiment-aware detection systems. Without ground truth emotional annotations, researchers cannot train supervised models to recognize emotional manipulation patterns, cannot evaluate whether sentiment features improve detection performance, and cannot analyze which emotional tactics are most effective for different attack types or target populations. The creation of datasets with rich emotional annotations represents a critical need for advancing phishing detection research.

\subsubsection{Multi-Modal Integration}

Few datasets provide comprehensive integration of all relevant phishing indicators in standardized, analysis-ready formats \cite{oest2020phishfarm}. Ideal datasets would include: complete .eml files preserving headers, body, and attachments; parsed structured representations of headers with authentication results; extracted and normalized text content; rendered HTML with screenshots; extracted URLs with reputation scores; and attachment metadata and static analysis results. Most existing datasets provide only subsets of this information, requiring researchers to choose between comprehensive feature analysis (possible only with complete .eml files) and convenience (processed datasets with pre-extracted features).

\subsubsection{Longitudinal Attack Evolution}

Limited availability of datasets tracking the evolution of specific phishing campaigns over time \cite{ramzan2009phishing}. Understanding how attacks adapt to defenses, how campaigns evolve across multiple waves, and how attackers respond to user education requires longitudinal data that most collections lack. Ramzan's work on phishing countermeasures noted that static datasets provide snapshots but miss the dynamic co-evolution of attacks and defenses that characterizes real-world security.

\subsubsection{Cross-Platform Consistency}

Most datasets focus exclusively on email-based phishing, with limited coverage of SMS phishing (smishing), social media phishing, messaging platform attacks, or voice phishing (vishing) that employ similar psychological tactics through different delivery mechanisms \cite{alnajim2021cross}. Alnajim and Zulkernine's work on cross-platform phishing detection demonstrated that while technical indicators differ across platforms, emotional manipulation strategies remain consistent, suggesting that sentiment-aware approaches might generalize across platforms more effectively than technical feature-based approaches.

\subsubsection{Adversarial Robustness Examples}

Insufficient representation of adversarially-crafted emails specifically designed to evade detection systems \cite{nelson2008adversarial}. While datasets include naturally occurring phishing that happens to evade detection, few include systematically generated adversarial examples created through techniques like gradient-based perturbation, synonym substitution, or strategic content injection. Nelson et al.'s foundational work on adversarial machine learning emphasized that models trained only on naturally occurring examples often exhibit poor robustness to deliberate evasion attempts.

\subsection{Dataset Evolution Summary}

Table \ref{tab:phishing_datasets} summarizes the evolution of datasets in phishing detection research, from historical legacy corpora through modern curated collections and synthetic generation approaches. This evolution reflects the field's maturation from opportunistic repurposing of existing email collections toward purposeful construction of comprehensive, representative, and well-annotated corpora designed specifically for phishing detection research.

\begin{table}[ht]
\centering
\caption{Evolution of Datasets in Phishing Detection Research.}
\label{tab:phishing_datasets}
\small
\begin{tabular}{|p{2.3cm}|p{2cm}|p{2.4cm}|p{1.5cm}|p{4.5cm}|}
\hline
\textbf{Dataset / Corpus} & \textbf{Year / Source} & \textbf{Size \& Content} & \textbf{Access} & \textbf{Key Features \& Limitations} \\ \hline
\multicolumn{5}{|c|}{\textbf{Legacy \& Historical Datasets}} \\ \hline
Enron E-mail Corpus & 2004 (Enron litigation) & $\sim$500K corporate emails (benign only) & Public & Foundational for baseline patterns; outdated communication styles, no phishing samples, corporate-centric language \\ \hline
SpamAssassin Public Corpus & 2002 (Apache) & $\sim$6K emails (spam + ham) & Public & Early spam filtering research; small scale, predates modern phishing techniques, limited attack diversity \\ \hline
Nazario Phishing Corpus & 2006 (J. Nazario) & $\sim$2K phishing emails & Public & First phishing-specific dataset; historically significant but severely outdated, reflects 2004-2006 attack techniques \\ \hline
\multicolumn{5}{|c|}{\textbf{Community-Driven \& Collaborative Datasets}} \\ \hline
PhishTank & Ongoing (OpenDNS/Cisco) & Continuous URL feeds + samples & Public API & Real-time updates, global coverage; primarily URL-focused, lacks complete .eml structure, potential label quality issues \\ \hline
APWG eCrime Exchange & Ongoing (APWG members) & Large-scale URL/email feeds, campaign data & Restricted & Current threat intelligence, real-world attacks, high fidelity; access limited to qualified researchers, privacy restrictions \\ \hline
\multicolumn{5}{|c|}{\textbf{Modern Curated \& Large-Scale Datasets}} \\ \hline
EPVME Dataset & 2024 (Patra et al.) & 600K+ malicious \& benign samples & Research & Large-scale benchmark, diverse attack vectors, simulates vulnerabilities; partially synthetic, potential bias concerns \\ \hline
Champa Curated Collection & 2025 (Champa et al.) & 200K+ instances (7 aggregated datasets) & Research & Meta-dataset approach, standardized labels, cross-validation enabled; heterogeneous sources may introduce inconsistencies \\ \hline
E-PhishGen Framework & 2025 (Caripoti et al.) & Variable (\ac{LLM}-generated) & Framework & Generates realistic phishing on-demand, controlled characteristics, addresses ethical concerns; realism gaps, adversarial validity uncertain \\ \hline
\multicolumn{5}{|c|}{\textbf{Synthetic \& Augmented Generation}} \\ \hline
Caripoti Synthetic Dataset & 2024 (Caripoti) & 10K+ phishing \& legitimate, attack-type categorized & Research & Balanced attack type coverage, ground truth annotations; potential overfitting to generation assumptions \\ \hline
Industry Proprietary & 2015--present (Microsoft, Google, others) & Millions of real samples, continuous updates & Private & Operational scale, current attacks, high diversity; academic reproducibility limited, publication restrictions \\ \hline
\end{tabular}
\end{table}

The trajectory from early legacy corpora to modern curated and synthetic datasets reflects several broader trends: recognition that phishing detection requires purpose-built datasets rather than repurposed general email corpora, increasing scale and diversity to support deep learning approaches, growing emphasis on synthetic generation to address ethical and practical collection challenges, and emerging awareness that rich annotations beyond binary labels (including emotional manipulation tactics) are essential for next-generation detection systems.

However, a critical gap remains: despite growing recognition that emotional manipulation represents the fundamental mechanism through which phishing succeeds, and despite promising results from initial sentiment-aware detection approaches, no large-scale dataset currently provides fine-grained emotional annotations. This gap directly motivates the dataset construction work presented in subsequent chapters of this thesis.

\section{Summary and Research Gaps}

This chapter has provided a comprehensive examination of the state of the art in phishing detection, spanning technical foundations of email communication, the evolution and impact of phishing attacks, the progression of machine learning approaches from rule-based systems through transformer architectures, the emerging role of sentiment analysis, and the development of training datasets.


Several key themes emerge from this review. First, phishing is fundamentally a form of psychological manipulation. While technical features such as URLs, headers, and attachments receive substantial research attention, phishing fundamentally succeeds through psychological manipulation rather than technical sophistication. Emotional triggers, including fear, urgency, greed, and authority, represent the core mechanism of successful attacks.

Second, there has been a clear evolution toward representation learning. Detection approaches have progressed from manual rule creation and engineered feature extraction to automated representation learning via transformers. Each generation has improved performance but also introduced new challenges, with current transformer-based systems achieving impressive results, yet requiring large-scale training data and remaining vulnerable to adversarial evasion.

Third, state-of-the-art systems increasingly integrate multiple information sources, such as textual content, metadata, URLs, and structure, recognizing that sophisticated attacks can evade single-modality detection but struggle to simultaneously satisfy all constraints.

Finally, despite the centrality of emotional manipulation to phishing success, sentiment analysis remains underexplored. Initial